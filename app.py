import streamlit as st
import duckdb
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from pathlib import Path
import numpy as np
import warnings

warnings.filterwarnings("ignore", message="The keyword arguments have been deprecated.*")

# --- Oldal Konfigur√°ci√≥ ---
st.set_page_config(
    page_title="Dinamikus Portf√≥li√≥ Analiz√°tor",
    page_icon="üîÆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- K√©tnyelv≈± Tartalom (B≈êV√çTVE) ---
TRANSLATIONS = {
    "hu": {
        "page_title": "Dinamikus portf√≥li√≥ optimaliz√°ci√≥ elemz≈ë",
        "sidebar_header": "Vez√©rl≈ëpult",
        "portfolio_select": "V√°lassz egy \"hat√©kony\" portf√≥li√≥t:",
        "tab_intro": "Bevezet≈ë",
        "tab_historical": "Historikus/projekt√°lt faktorok",
        "tab_frontier": "Hat√©kony front",
        "tab_allocation": "Allok√°ci√≥ √©s k√©nyszerek",
        "tab_distribution": "Vagyoneloszl√°sok",
        "tab_diagnostics": "Diagnosztika",
        "intro_header": "A kvantitat√≠v munkafolyamat √°ttekint√©se",
        "step1_header": "1. L√©p√©s: Piaci modell (BVAR-MSH)",
        "step1_text": """
        A piaci dinamik√°k el≈ërejelz√©s√©hez egy Bayes-i Vektor Autoregresszi√≥s modellt haszn√°lunk Markov-rezsimv√°lt√≥s heteroszkedaszticit√°ssal (BVAR-MSH).
        - **Mi√©rt BVAR?** A Bayes-i keretrendszer lehet≈ëv√© teszi a prior hiedelmek be√©p√≠t√©s√©t, ami stabiliz√°lja a becsl√©st √©s figyelembe veszi a param√©terbizonytalans√°got.
        - **Mi√©rt MSH?** A p√©nz√ºgyi piacok volatilit√°sa nem √°lland√≥. Az MSH modell k√©pes megk√ºl√∂nb√∂ztetni a 'nyugodt' √©s 'p√°nik' piaci rezsimeket, √≠gy realisztikusabb kock√°zati el≈ërejelz√©seket ad.
        - **Eredm√©ny:** Egy nagysz√°m√∫, 60 h√≥napos, 14 v√°ltoz√≥s szcen√°ri√≥k√©szlet, amely a j√∂v≈ëbeli piaci p√°ly√°k lehets√©ges alakul√°s√°t √≠rja le.
        """,
        "step2_header": "2. L√©p√©s: N√©zetek be√©p√≠t√©se (Entr√≥pia Pooling)",
        "step2_text": """
        A BVAR-MSH modell 'objekt√≠v' szcen√°ri√≥it finomhangoljuk szubjekt√≠v piaci v√°rakoz√°sainkkal (n√©zetekkel). Az Entr√≥pia Pooling a szcen√°ri√≥k val√≥sz√≠n≈±s√©geit m√≥dos√≠tja, hogy azok megfeleljenek a k√©nyszereinknek, mik√∂zben a lehet≈ë legk√∂zelebb marad az eredeti eloszl√°shoz.
        
        **Konkr√©t n√©zeteink:**
        - **Arany (GLD):** √âves√≠tett √°tlaghozama `[2.9%, 3.3%]` k√∂z√© essen.
        - **R√∂vid √Ållampap√≠r (BIL):** A negat√≠v havi hozam val√≥sz√≠n≈±s√©ge legfeljebb `5%` legyen.
        - **√Ållamk√∂tv√©nyek (Treasury):** Az √∂sszes √°llamk√∂tv√©ny (BIL, SHY, IEF, TLT) √©ves√≠tett hozama `[3.8%, 4.1%]` k√∂z√© essen (a z√©r√≥ k√∂r√ºli term pr√©mium n√©zet√ºnket t√ºkr√∂zve).
        - **Relat√≠v Teljes√≠tm√©ny:**
            - A r√©szv√©nyek (SPY, IWM) √°tlaghozama legyen magasabb, mint a k√∂tv√©nyek√©.
            - A r√©szv√©nyek √°tlagos volatilit√°sa is legyen magasabb.
            - A r√©szv√©nyek √°tlaghozam√°nak fels≈ë korl√°tja `8%`.
        - **Volatilit√°si Rangsor:** A k√∂tv√©nyek volatilit√°sa a H/2-ben minim√°lis (`œÉ(SHY) < œÉ(BIL) < œÉ(IEF) < œÉ(TLT)`).
        """,
        "step3_header": "3. L√©p√©s: Dinamikus optimaliz√°ci√≥",
        "step3_text": """
        A n√©zetekkel s√∫lyozott szcen√°ri√≥kon egy t√∂bbperi√≥dusos portf√≥li√≥-optimaliz√°ci√≥t hajtunk v√©gre.
        - **C√©lf√ºggv√©ny:** Komplex, hibrid c√©lf√ºggv√©nyt haszn√°lunk, ami a termin√°lis vagyon maximaliz√°l√°sa √©s farokkock√°zat√°nak (cCVaR) minimaliz√°l√°sa mellett b√ºnteti a p√°lya menti t√∫lzott havi kock√°zatot √©s a magas forg√°si sebess√©get.
        - **K√©nyszerek:**
            - **Hard (id≈ëben v√°ltoz√≥):** Portf√≥li√≥-√∂sszet√©teli korl√°tok (pl. `min_treasury`), amelyek az id≈ë el≈ërehaladt√°val lazulnak. A **b√°zisportf√≥li√≥k** konvex kombin√°ci√≥j√°nak optimaliz√°l√°sa garant√°lja ezek betart√°s√°t.
            - **Soft (nemline√°ris):** A c√©lf√ºggv√©ny b√ºntet≈ëtagjai √°ltal kezelt elv√°r√°sok (pl. havi kock√°zati s√°v).
        - **Technol√≥gia:** A komplexit√°s miatt modern, gradiens-alap√∫ optimaliz√°l√≥t (PyTorch/ADAM) haszn√°lunk, GPU-gyors√≠t√°ssal.
        """,
        "historical_header": "Historikus teljes√≠tm√©ny (100-r√≥l indul√≥ index)",
        "asset_select": "V√°lasszon eszk√∂z√∂ket:",
        "show_pi": "Predikci√≥s intervallumok mutat√°sa",
        "frontier_xaxis": "√âves√≠tett kock√°zat (cCVaR)",
        "frontier_yaxis": "√âves√≠tett hozam",
        "allocation_title": "Dinamikus s√∫lyp√°lya",
        "constraints_title": "Aktu√°lis k√©nyszerek (h√≥nap: {month})",
        "wealth_dist_title": "Termin√°lis vagyon eloszl√°sa",
        "wealth_dist_xaxis": "Termin√°lis vagyon (1$ befektet√©sb≈ël)",
        "fanchart_title": "Portf√≥li√≥ √©rt√©k√©nek el≈ërejelz√©se (fanchart)",
        "date_axis": "D√°tum",
        "weight_axis": "S√∫ly",
        "value_axis": "√ârt√©k",
        "indexed_value_axis": "Index (100-r√≥l indul)",
        "diagnostics_summary_title": "Portf√≥li√≥k diagnosztikai √∂sszefoglal√≥ja",
        "convergence_title": "Optimaliz√°ci√≥ konvergenci√°ja",
        "loss_type_select": "V√°lasszon vesztes√©g-komponenst:",
        "data_error_title": "Hiba az adatf√°jlok bet√∂lt√©sekor!",
        "data_error_body": "A `streamlit_data` mappa vagy annak tartalma nem tal√°lhat√≥. K√©rj√ºk, ellen≈ërizze a telep√≠t√©st.",
        "stats_header": "Portf√≥li√≥ statisztik√°k",
        "monthly_stats": "Kiv√°lasztott h√≥nap",
        "total_path": "Teljes 60 h√≥napos p√°lya",
        "monthly_er": "Havi E[R]",
        "annualized_er": "√âves√≠tett E[R]",
        "monthly_ccvar": "Havi cCVaR",
        "annualized_ccvar": "√âves√≠tett cCVaR",
        "monthly_cvar": "Havi CVaR",
        "annualized_cvar": "√âves√≠tett CVaR",
        "value_col": "√ârt√©k",
    },
    "en": {
        "page_title": "Dynamic Portfolio Optimization Analyzer",
        "sidebar_header": "Controls",
        "portfolio_select": "Select an \"Efficient\" Portfolio:",
        "tab_intro": "Introduction",
        "tab_historical": "Historical and Projected Factors",
        "tab_frontier": "Efficient Frontier",
        "tab_allocation": "Allocation & Constraints",
        "tab_distribution": "Wealth Distribution",
        "tab_diagnostics": "Diagnostics",
        "intro_header": "The Quantitative Workflow Overview",
        "step1_header": "Step 1: Market Model (BVAR-MSH)",
        "step1_text": """
        To forecast market dynamics, we use a Bayesian Vector Autoregressive model with Markov-Switching Heteroscedasticity (BVAR-MSH).
        - **Why BVAR?** The Bayesian framework allows incorporating prior beliefs, stabilizing estimation, and accounting for parameter uncertainty.
        - **Why MSH?** Financial market volatility is not constant. The MSH model can distinguish between 'calm' and 'panic' regimes, leading to more realistic risk forecasts.
        - **Result:** A large set of 60-month, 14-variable scenarios describing the potential evolution of future market paths.
        """,
        "step2_header": "Step 2: Incorporating Views (Entropy Pooling)",
        "step2_text": """
        We refine the 'objective' scenarios from the BVAR-MSH model with our subjective market expectations (views). Entropy Pooling adjusts scenario probabilities to satisfy our constraints while minimally deviating from the original distribution.
        
        **Our Specific Views:**
        - **Gold (GLD):** Annualized average return to fall between `[2.9%, 3.3%]`.
        - **Short-Term T-Bill (BIL):** Probability of a negative monthly return to be at most `5%`.
        - **Treasuries:** All treasury bonds (BIL, SHY, IEF, TLT) to have an annualized return between `[3.8%, 4.1%]` (reflecting our near-zero term premium view).
        - **Relative Performance:**
            - The average return of equities (SPY, IWM) should be higher than bonds.
            - The average volatility of equities should also be higher.
            - The upper cap for the average equity return is `8%`.
        - **Volatility Ranking:** Bond volatility minima at H/2 (`œÉ(SHY) < œÉ(BIL) < œÉ(IEF) < œÉ(TLT)`).
        """,
        "step3_header": "Step 3: Dynamic Optimization",
        "step3_text": """
        We perform a multi-period portfolio optimization on the view-weighted scenarios.
        - **Objective Function:** A complex, hybrid objective that maximizes terminal wealth and minimizes its tail risk (cCVaR), while also penalizing excessive path-dependent monthly risk and high turnover.
        - **Constraints:**
            - **Hard (Time-Varying):** Portfolio composition limits (e.g., `min_treasury`) that relax over time, guaranteed by optimizing a convex combination of **basis portfolios**.
            - **Soft (Non-Linear):** Expectations managed by penalty terms in the objective function (e.g., monthly risk bands).
        - **Technology:** We use a modern, gradient-based optimizer (PyTorch/ADAM) with GPU acceleration.
        """,
        "historical_header": "Historical Performance (Indexed to 100)",
        "asset_select": "Select Assets:",
        "show_pi": "Show Prediction Intervals",
        "frontier_xaxis": "Annualized Risk (cCVaR)",
        "frontier_yaxis": "Annualized Return",
        "allocation_title": "Dynamic Allocation Path",
        "constraints_title": "Active Constraints (Month: {month})",
        "wealth_dist_title": "Terminal Wealth Distribution",
        "wealth_dist_xaxis": "Terminal Wealth (from 1$ investment)",
        "fanchart_title": "Portfolio Value Projection (Fanchart)",
        "date_axis": "Date",
        "weight_axis": "Weight",
        "value_axis": "Value",
        "indexed_value_axis": "Index (starts at 100)",
        "diagnostics_summary_title": "Portfolio Diagnostics Summary",
        "convergence_title": "Optimization Convergence",
        "loss_type_select": "Select Loss Component:",
        "data_error_title": "Error Loading Data Files!",
        "data_error_body": "The `streamlit_data` directory or its contents were not found. Please check your installation.",
        "stats_header": "Portfolio Statistics",
        "monthly_stats": "Selected Month",
        "total_path": "Full 60-Month Path",
        "monthly_er": "Monthly E[R]",
        "annualized_er": "Annualized E[R]",
        "monthly_ccvar": "Monthly cCVaR",
        "annualized_ccvar": "Annualized cCVaR",
        "monthly_cvar": "Monthly CVaR",
        "annualized_cvar": "Annualized CVaR",
        "value_col": "Value",
    }
}

# --- Minim√°l CSS ---
st.markdown("""
<style>
    h1 { text-align: center; font-weight: bold; }
    /* A label elrejt√©se a radio gombokn√°l */
    div[role="radiogroup"] > label {
        display: true;
    }
</style>
""", unsafe_allow_html=True)

@st.cache_data
def get_color_map():
    """Konzisztens sz√≠nlek√©pez√©s az √∂sszes eszk√∂zh√∂z."""
    # A _con-t a session_state-b≈ël kell el√©rni a cache-elt f√ºggv√©nyen bel√ºl is
    all_assets_df = run_query("SELECT name FROM dim_assets WHERE type = 'asset_return'")
    if all_assets_df.empty:
        return {}
    asset_names = sorted(all_assets_df['name'].unique())
    palette = px.colors.qualitative.Plotly
    return {asset: palette[i % len(palette)] for i, asset in enumerate(asset_names)}

def apply_fillcolor_for_area(fig, color_map):
    """
    Fel√ºlb√≠r√°lja az area chart trace-ek sz√≠n√©t √©s √°ttetsz≈ës√©g√©t a megadott
    sz√≠nlek√©pez√©s alapj√°n a jobb olvashat√≥s√°g √©rdek√©ben.
    """
    for trace in fig.data:
        if trace.name in color_map:
            # A fillcolor-t a vonal sz√≠n√©hez igaz√≠tjuk √©s az opacity-t 1-re √°ll√≠tjuk
            trace.update(fillcolor=color_map[trace.name], opacity=1)


# --- Adatb√°zis Kapcsolat ---
@st.cache_resource
def get_db_connection():
    # A nyelvi ford√≠t√°st itt m√©g nem haszn√°lhatjuk, ez√©rt angolul √≠rjuk ki a hib√°t
    data_dir = Path(__file__).parent / "streamlit_data"
    db_path = str(data_dir / "database.duckdb")
    if not data_dir.exists() or not Path(db_path).exists():
        st.error(TRANSLATIONS['en']['data_error_body'], icon="üö®")
        return None
    
    con = duckdb.connect(database=db_path, read_only=True)
    return con

# --- Adatlek√©rdez≈ë F√ºggv√©ny ---
@st.cache_data
def run_query(query, **params):
    # A kapcsolatot a session state-b≈ël vessz√ºk, hogy ne kelljen glob√°lis v√°ltoz√≥t haszn√°lni
    if '_con' not in st.session_state or st.session_state._con is None: return pd.DataFrame()
    return st.session_state._con.execute(query, list(params.values())).fetchdf()

# --- App T√∂rzse ---
st.session_state._con = get_db_connection()
if not st.session_state._con:
    st.stop()

# --- Nyelvv√°laszt√≥ √©s Log√≥ a Sidebar-ban ---
logo_path = Path(__file__).parent / ".streamlit" / "optimization.png"
if logo_path.exists(): st.sidebar.image(str(logo_path))

if 'lang' not in st.session_state: st.session_state.lang = "hu"
lang_options = {"Magyar": "hu", "English": "en"}
selected_lang_str = st.sidebar.radio("Nyelv / Language", options=list(lang_options.keys()), horizontal=True)
st.session_state.lang = lang_options[selected_lang_str]
t = TRANSLATIONS[st.session_state.lang]

# --- Oldal C√≠me √©s Sidebar Vez√©rl≈ëk ---
st.title(t['page_title'])
st.sidebar.header(t['sidebar_header'])
frontier_df = run_query("SELECT * FROM fact_efficient_frontier")

# --- Portf√≥li√≥ kiv√°laszt√°s (stabil √°llapot) ---
st.session_state.portfolio_id = st.sidebar.select_slider(
    t['portfolio_select'],
    options=sorted(frontier_df['portfolio_id'].unique()),
    value=st.session_state.get('portfolio_id', int(frontier_df['portfolio_id'].median()))
)
selected_portfolio_id = st.session_state.portfolio_id

# --- Kontrol√°lt "Tabs" (radio, v√≠zszintesen), stabil f√≥kusz ---
tab_keys = ["intro", "historical", "frontier", "allocation", "distribution", "diagnostics"]
tab_titles = [f"üìë {t[f'tab_{k}']}" for k in tab_keys]
active_tab_title = st.radio(
    label="Navigation", label_visibility="collapsed",
    options=tab_titles, horizontal=True, key='active_tab'
)
active_key = tab_keys[tab_titles.index(active_tab_title)]

# --- Bevezet≈ë ---
if active_key == "intro":
    st.header(t['intro_header'])
    st.markdown("---")
    col1, col2, col3 = st.columns(3, gap="large")
    with col1:
        st.subheader(t['step1_header'], divider='blue')
        st.markdown(t['step1_text'])
    with col2:
        st.subheader(t['step2_header'], divider='green')
        st.markdown(t['step2_text'])
    with col3:
        st.subheader(t['step3_header'], divider='orange')
        st.markdown(t['step3_text'])

# --- Historikus adatok (B≈êV√çTVE) ---
if active_key == "historical":
    st.subheader(t['historical_header'])
    asset_types_df = run_query("SELECT symbol, name, type FROM dim_assets")
    symbol_to_name = dict(zip(asset_types_df['symbol'], asset_types_df['name']))
    name_to_symbol = {v: k for k, v in symbol_to_name.items()}
    symbol_to_type = dict(zip(asset_types_df['symbol'], asset_types_df['type']))

    c1, c2 = st.columns([3, 1])
    with c1:
        default_assets = ['SPY', 'TLT', 'GLD', 'T10Y2Y']
        selected_asset_names = st.multiselect(
            t['asset_select'],
            options=sorted(asset_types_df['name'].unique()),
            default=[symbol_to_name.get(s, s) for s in default_assets]
        )
    with c2:
        show_pi = st.checkbox(t['show_pi'], value=False)
    
    if selected_asset_names:
        selected_symbols = [name_to_symbol[n] for n in selected_asset_names]
        performance_symbols = [s for s in selected_symbols if symbol_to_type.get(s) == 'asset_return']
        macro_symbols = [s for s in selected_symbols if symbol_to_type.get(s) != 'asset_return']
        
        fig = make_subplots(specs=[[{"secondary_y": True}]])
        
        if performance_symbols:
            hist_perf_df = run_query("SELECT d.date, a.name, p.indexed_value FROM fact_historical_performance p JOIN dim_assets a ON p.symbol = a.symbol JOIN dim_dates d ON p.date = d.date WHERE p.symbol IN (SELECT * FROM UNNEST(?))", symbols=performance_symbols)
            for name in hist_perf_df['name'].unique():
                df_subset = hist_perf_df[hist_perf_df['name'] == name]
                fig.add_trace(go.Scatter(x=df_subset['date'], y=df_subset['indexed_value'], name=name, mode='lines'), secondary_y=False)
            
            if show_pi:
                quantiles_df = run_query("SELECT d.date, a.name, q.* FROM fact_asset_forecast_quantiles q JOIN dim_assets a ON q.symbol = a.symbol JOIN dim_dates d ON q.timestep_index = d.timestep_index WHERE d.timestep_type = 'future' AND q.symbol IN (SELECT * FROM UNNEST(?))", symbols=performance_symbols)
                for name in quantiles_df['name'].unique():
                    df_subset = quantiles_df[quantiles_df['name'] == name]
                    fig.add_trace(go.Scatter(x=df_subset['date'], y=df_subset['p50'], name=f"{name} Median", line=dict(dash='dot')), secondary_y=False)
                    fig.add_trace(go.Scatter(x=df_subset['date'], y=df_subset['p95'], line=dict(width=0), showlegend=False), secondary_y=False)
                    fig.add_trace(go.Scatter(x=df_subset['date'], y=df_subset['p05'], fill='tonexty', fillcolor='rgba(255, 0, 0, 0.1)', line=dict(width=0), showlegend=False, name=f"{name}_90pi"), secondary_y=False)

        if macro_symbols:
            hist_macro_df = run_query("SELECT d.date, a.name, m.value FROM fact_historical_macro m JOIN dim_assets a ON m.symbol = a.symbol JOIN dim_dates d ON m.date = d.date WHERE m.symbol IN (SELECT * FROM UNNEST(?))", symbols=macro_symbols)
            for name in hist_macro_df['name'].unique():
                df_subset = hist_macro_df[hist_macro_df['name'] == name]
                fig.add_trace(go.Scatter(x=df_subset['date'], y=df_subset['value'], name=name, line=dict(dash='dot')), secondary_y=True)

        fig.update_layout(legend_title_text="", xaxis_title=t['date_axis'])
        fig.update_yaxes(title_text=t['indexed_value_axis'], secondary_y=False)
        fig.update_yaxes(title_text=t.get('value_axis', 'Value') if macro_symbols else "", secondary_y=True, showgrid=False)
        st.plotly_chart(fig)#, width='stretch')

# --- Hat√©kony front ---
if active_key == "frontier":
    fig_frontier = px.line(frontier_df.sort_values("annualized_risk_ccvar"), x="annualized_risk_ccvar", y="annualized_return", markers=True, custom_data=['portfolio_id']).add_scatter(x=frontier_df['annualized_risk_ccvar'], y=frontier_df['annualized_return'], mode='text', text=frontier_df['portfolio_id'], textposition='top center', showlegend=False)
    fig_frontier.update_layout(title="<b>" + t['tab_frontier'] + "</b>", xaxis_title=t['frontier_xaxis'], yaxis_title=t['frontier_yaxis'], xaxis_tickformat='.1%', yaxis_tickformat='.1%')
    fig_frontier.update_traces(hovertemplate="<b>Portfolio %{customdata[0]}</b><br>Return: %{y:.2%}<br>Risk (cCVaR): %{x:.2%}<extra></extra>")
    st.plotly_chart(fig_frontier)#, width='stretch')

# --- Allok√°ci√≥ √©s K√©nyszerek (V√âGLEGES) ---
if active_key == "allocation":
    st.subheader(f"{t['allocation_title']} P{selected_portfolio_id}")
    asset_color_map = get_color_map()
    
    col1, col2 = st.columns([2, 1], gap="large")
    with col1:
        weights_df = run_query("SELECT dd.date, da.name, pw.weight FROM fact_portfolio_weights AS pw JOIN dim_assets AS da ON pw.symbol = da.symbol JOIN dim_dates AS dd ON pw.timestep_index = dd.timestep_index WHERE pw.portfolio_id = ? AND dd.timestep_type = 'future'", portfolio_id=int(selected_portfolio_id))
        assets_in_portfolio = weights_df[weights_df['weight'] > 0.001]['name'].unique()
        if not weights_df.empty:
            fig_weights = px.area(weights_df[weights_df['name'].isin(assets_in_portfolio)], x='date', y='weight', color='name', category_orders={"name": sorted(assets_in_portfolio)}, color_discrete_map=asset_color_map)
            apply_fillcolor_for_area(fig_weights, asset_color_map)
            fig_weights.update_layout(yaxis_tickformat=".0%", legend_title_text="", xaxis_title=t['date_axis'], yaxis_title=t['weight_axis'], legend=dict(orientation="h", yanchor="bottom", y=-0.3, xanchor="right", x=1))
            st.plotly_chart(fig_weights)#, width='stretch')
    
    with col2:
        st.subheader(t['stats_header'])
        month = st.slider(f"{t.get('monthly_stats', 'Month')}", 1, 60, 1, key="month_slider")

        monthly_stats_df = run_query("SELECT * FROM fact_monthly_portfolio_stats WHERE portfolio_id = ? AND timestep_index = ?", portfolio_id=int(selected_portfolio_id), timestep_index=int(month))
        total_stats_df = run_query("SELECT * FROM fact_diagnostics_summary WHERE portfolio_id = ?", portfolio_id=int(selected_portfolio_id))
        
        if not monthly_stats_df.empty and not total_stats_df.empty:
            stats = {
                (t['monthly_stats'], t['monthly_er']): f"{monthly_stats_df['monthly_er'].iloc[0]:.2%}",
                (t['monthly_stats'], t['annualized_er']): f"{(1 + monthly_stats_df['monthly_er'].iloc[0])**12 - 1:.2%}",
                (t['monthly_stats'], t['monthly_ccvar']): f"{monthly_stats_df['monthly_ccvar'].iloc[0]:.2%}",
                (t['monthly_stats'], t['annualized_ccvar']): f"{monthly_stats_df['monthly_ccvar'].iloc[0] * np.sqrt(12):.2%}",
                (t['monthly_stats'], t['monthly_cvar']): f"{monthly_stats_df['monthly_std_cvar'].iloc[0]:.2%}",
                (t['monthly_stats'], t['annualized_cvar']): f"{-(((1 + monthly_stats_df['monthly_er'].iloc[0])**12 - 1) - (monthly_stats_df['monthly_ccvar'].iloc[0] * np.sqrt(12))):.2%}",
                (t['total_path'], t['annualized_er']): f"{total_stats_df['Evesitett_Hozam'].iloc[0]:.2%}",
                (t['total_path'], t['annualized_ccvar']): f"{total_stats_df['Evesitett_Kockazat_cCVaR'].iloc[0]:.2%}",
                (t['total_path'], t['annualized_cvar']): f"{total_stats_df.get('Evesitett_Std_CVaR', [np.nan]).iloc[0]:.2%}",
            }
            stats_df = pd.DataFrame.from_dict(stats, orient='index', columns=[t['value_col']])
            stats_df.index = pd.MultiIndex.from_tuples(stats_df.index)
            st.dataframe(stats_df)#, width='stretch')

    col3, col4 = st.columns([2, 1], gap="large")
    with col3:
        if 'weights_df' in locals() and not weights_df.empty:
            weights_for_month = weights_df[weights_df['date'] == weights_df['date'].unique()[month - 1]]
            weights_for_pie = weights_for_month[weights_for_month['weight'] > 0.001]
            if not weights_for_pie.empty:
                pie_title = f"{t['tab_allocation']} ({t.get('monthly_stats', 'Month')} {month})"
                fig_pie = px.pie(weights_for_pie, names='name', values='weight', title=f"<b>{pie_title}</b>", color='name', category_orders={"name": sorted(assets_in_portfolio)}, color_discrete_map=asset_color_map)
                fig_pie.update_traces(textposition='inside', textinfo='percent+label', sort=False)
                fig_pie.update_layout(showlegend=False, margin=dict(t=40, b=20, l=20, r=20))
                st.plotly_chart(fig_pie)#, width='stretch')
    with col4:
        st.subheader(t['constraints_title'].format(month=month))
        cs_level = ("Szigor√∫" if st.session_state.lang == 'hu' else "Strict") if month <= 24 else (("Laza" if st.session_state.lang == 'hu' else "Relaxed") if month <= 48 else ("Nagyon laza" if st.session_state.lang == 'hu' else "Very Relaxed"))
        cs_values = {'min_treasury': 0.50, 'max_gld': 0.25, 'min_gld': 0.10, 'min_bil_shy': 0.10} if month <= 24 else ({'min_treasury': 0.45, 'max_gld': 0.30, 'min_gld': 0.08, 'min_bil_shy': 0.08} if month <= 48 else {'min_treasury': 0.40, 'max_gld': 0.35, 'min_gld': 0.05, 'min_bil_shy': 0.05})
        st.markdown(f"##### K√©nyszer: `{cs_level}`")
        st.markdown(f"- **Min. Treasury:** `{cs_values['min_treasury']:.0%}`")
        st.markdown(f"- **Min. Gold:** `{cs_values['min_gld']:.0%}`")
        st.markdown(f"- **Max. Gold:** `{cs_values['max_gld']:.0%}`")
        st.markdown(f"- **Min. Cash-like (BIL+SHY):** `{cs_values['min_bil_shy']:.0%}`")
        st.markdown(f"- **Max. egyedi eszk√∂z s√∫ly:** `40%`")

# --- J√∂v≈ëbeli eloszl√°sok ---
if active_key == "distribution":
    st.subheader(f"{t['wealth_dist_title']} - P{selected_portfolio_id}")
    # A hossz√∫ query-t haszn√°ljuk a biztons√°g kedv√©√©rt
    terminal_wealth_df = run_query("""
        WITH PortfolioReturns AS (
            SELECT s.scenario_id, SUM(s.return_value * w.weight) as portfolio_return
            FROM fact_bvar_scenarios AS s
            JOIN fact_portfolio_weights AS w
              ON s.timestep_index = w.timestep_index AND s.symbol = w.symbol
            WHERE w.portfolio_id = ?
            GROUP BY s.scenario_id, s.timestep_index
        ),
        CumulativeWealth AS (
            SELECT scenario_id, PRODUCT(1 + portfolio_return) as terminal_wealth
            FROM PortfolioReturns GROUP BY scenario_id
        )
        SELECT terminal_wealth FROM CumulativeWealth
    """, portfolio_id=int(selected_portfolio_id))
    if not terminal_wealth_df.empty:
        fig_dist = px.histogram(terminal_wealth_df, x="terminal_wealth", nbins=60, histnorm='probability density', opacity=0.4)
        fig_dist.update_traces(marker_line_color='#1f77b4', marker_line_width=0.75)
        fig_dist.update_layout(xaxis_title=t['wealth_dist_xaxis'], yaxis_title=t.get('density', 'Density'))
        st.plotly_chart(fig_dist)#, width='stretch')

    st.subheader(f"{t['fanchart_title']} - P{selected_portfolio_id}")
    fanchart_df = run_query("""
        WITH PortfolioReturns AS (
            SELECT s.scenario_id, s.timestep_index, SUM(s.return_value * w.weight) as portfolio_return
            FROM fact_bvar_scenarios AS s
            JOIN fact_portfolio_weights AS w
              ON s.timestep_index = w.timestep_index AND s.symbol = w.symbol
            WHERE w.portfolio_id = ?
            GROUP BY s.scenario_id, s.timestep_index
        ),
        PathWealth AS (
             SELECT
                scenario_id, timestep_index,
                EXP(SUM(LN(GREATEST(1 + portfolio_return, 1e-9))) OVER (PARTITION BY scenario_id ORDER BY timestep_index)) as path_wealth
            FROM PortfolioReturns
        ),
        Quantiles AS (
            SELECT
                timestep_index,
                quantile_cont(path_wealth, 0.05) AS p05, quantile_cont(path_wealth, 0.25) AS p25,
                quantile_cont(path_wealth, 0.50) AS p50, quantile_cont(path_wealth, 0.75) AS p75,
                quantile_cont(path_wealth, 0.95) AS p95
            FROM PathWealth GROUP BY timestep_index
        )
        SELECT d.date, q.* FROM Quantiles q
        JOIN dim_dates d ON q.timestep_index = d.timestep_index
        WHERE d.timestep_type = 'future' ORDER BY d.date
    """, portfolio_id=int(selected_portfolio_id))
    if not fanchart_df.empty:
        dates = pd.to_datetime(fanchart_df['date'])
        fig_fan = go.Figure([
            go.Scatter(x=dates, y=fanchart_df['p95'], mode='lines', line=dict(width=0), showlegend=False),
            go.Scatter(x=dates, y=fanchart_df['p05'], mode='lines', line=dict(width=0), fillcolor='rgba(31, 119, 180, 0.2)', fill='tonexty', name='90% Conf. Interval', hoverinfo='none'),
            go.Scatter(x=dates, y=fanchart_df['p75'], mode='lines', line=dict(width=0), showlegend=False),
            go.Scatter(x=dates, y=fanchart_df['p25'], mode='lines', line=dict(width=0), fillcolor='rgba(31, 119, 180, 0.4)', fill='tonexty', name='50% Conf. Interval', hoverinfo='none'),
            go.Scatter(x=dates, y=fanchart_df['p50'], mode='lines', line=dict(color='#1f77b4', width=3), name='Median (P50)')
        ])
        fig_fan.update_layout(yaxis_title=t['value_axis'], xaxis_title=t['date_axis'], legend_title_text="Confidence Interval", hovermode="x unified")
        st.plotly_chart(fig_fan)#, width='stretch')

# --- Diagnosztika ---
if active_key == "diagnostics":
    st.subheader(t['diagnostics_summary_title'])
    diagnostics_df = run_query("SELECT * FROM fact_diagnostics_summary")
    if not diagnostics_df.empty:
        format_mapping = { "Evesitett_Hozam": "{:.2%}", "Evesitett_Kockazat_cCVaR": "{:.2%}", "Evesitett_Std_CVaR": "{:.2%}", "Maximalis_Kenyszer_Sertes": "{:.2e}", "Atlagos_Havi_Forgas": "{:.2%}", "Atlagos_Havi_cCVaR": "{:.2%}", "Maximalis_Havi_cCVaR": "{:.2%}", "Atlagos_Koncentracio_HHI": "{:.3f}" }
        st.dataframe(diagnostics_df.style.format(format_mapping))#, width='stretch')
    
    st.subheader(f"{t['convergence_title']} - P{selected_portfolio_id}")
    convergence_df = run_query("SELECT * FROM fact_convergence WHERE portfolio_id = ?", portfolio_id=int(selected_portfolio_id))
    if not convergence_df.empty:
        loss_types = sorted(convergence_df['loss_type'].unique())
        default_loss = 'total_loss' if 'total_loss' in loss_types else loss_types[0]
        selected_loss = st.selectbox(t['loss_type_select'], loss_types, index=loss_types.index(default_loss))
        fig_conv = px.line(convergence_df[convergence_df['loss_type'] == selected_loss], x="Epoch", y="value", title=f"{selected_loss}")
        st.plotly_chart(fig_conv)#, width='stretch')